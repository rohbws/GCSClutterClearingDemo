{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rohanbosworth/Downloads/iris_and_bins-master', '/home/rohanbosworth/Downloads/iris_and_bins-master/~/manipulation', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/rohanbosworth/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages/IPython/extensions', '/home/rohanbosworth/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.insert(0, \"/home/rohanbosworth/manipulation/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
     ]
    }
   ],
   "source": [
    "from pydrake.all import (DiagramBuilder, \n",
    "                         AddMultibodyPlantSceneGraph, \n",
    "                         Parser, \n",
    "                         LoadModelDirectives,\n",
    "                         ProcessModelDirectives,\n",
    "                         AddDefaultVisualization,\n",
    "                         Meldis, PackageMap, RobotDiagramBuilder\n",
    ")\n",
    "from pydrake.all import SceneGraphCollisionChecker, VisibilityGraph\n",
    "\n",
    "from manipulation import ConfigureParser\n",
    "import os\n",
    "def plant_builder(use_meshcat = False, use_rohan_scenario = True):\n",
    "    if use_meshcat:\n",
    "        meldis = Meldis()\n",
    "        meshcat = meldis.meshcat\n",
    "    builder = RobotDiagramBuilder()\n",
    "    plant = builder.plant()\n",
    "    scene_graph = builder.scene_graph()\n",
    "    parser = builder.parser()\n",
    "    ConfigureParser(parser)\n",
    "    if use_rohan_scenario:\n",
    "        directives_file = './models/iiwa14_rohan_cheap.dmd.yaml'\n",
    "    else:\n",
    "        directives_file = './models/iiwa14_david_cheap.dmd.yaml'\n",
    "        \n",
    "    parser.package_map().AddPackageXml(filename=os.path.abspath(\"./models/package.xml\"))\n",
    "    directives = LoadModelDirectives(directives_file)\n",
    "    models = ProcessModelDirectives(directives, plant, parser)\n",
    "    plant.Finalize()\n",
    "    if use_meshcat:\n",
    "        visualizer = AddDefaultVisualization(builder.builder(), meshcat)\n",
    "    diagram = builder.Build()\n",
    "    diagram_context = diagram.CreateDefaultContext()\n",
    "    plant_context = plant.GetMyContextFromRoot(diagram_context)\n",
    "    diagram.ForcedPublish(diagram_context)\n",
    "    return plant, scene_graph, diagram, diagram_context, plant_context, meshcat if use_meshcat else None\n",
    "\n",
    "\n",
    "USE_ROHAN = False\n",
    "plant, scene_graph, diagram, diagram_context, plant_context, meshcat = plant_builder(True, USE_ROHAN)\n",
    "scene_graph_context = scene_graph.GetMyMutableContextFromRoot(\n",
    "    diagram_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import (RigidTransform,\n",
    "                         RotationMatrix,\n",
    "                         InverseKinematics,\n",
    "                         Solve,\n",
    "                         Role,\n",
    "                         VPolytope,\n",
    "                         HPolyhedron\n",
    "                         )\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def point_in_regions(pt, regions):\n",
    "    \"\"\"\n",
    "    check whether point in region\n",
    "    \"\"\"\n",
    "    for r in regions:\n",
    "        if r.PointInSet(pt.reshape(-1,1)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def sample_in_union_of_polytopes(num_points, regions, aabb_limits, maxit = int(1e4), seed = 1234976512):\n",
    "    \"\"\"\n",
    "    sample in the union of polytopes\n",
    "    \"\"\"\n",
    "    #np.random.seed(seed)\n",
    "    dim = regions[0].ambient_dimension()\n",
    "    min_l = aabb_limits[0]\n",
    "    max_l = aabb_limits[1]\n",
    "    diff = max_l - min_l\n",
    "    pts = np.zeros((num_points, dim))\n",
    "    for i in range(num_points):\n",
    "        for it in range(maxit):\n",
    "            pt = min_l + np.random.rand(dim)*diff\n",
    "            if point_in_regions(pt, regions):\n",
    "                pts[i,:] = pt\n",
    "                break\n",
    "            if it == maxit-1:\n",
    "                print(\"[sample_in_union_of_polytopes] NO POINT FOUND\")\n",
    "                return None   \n",
    "    return pts\n",
    "\n",
    "def get_cvx_hulls_of_bodies(geometry_names, model_names, plant, scene_graph, scene_graph_context, scaling = 1):\n",
    "    \"\"\"\n",
    "    produce convex hulls of many bodies from plant\n",
    "    \"\"\"\n",
    "    inspector = scene_graph.model_inspector()\n",
    "    bodies_of_interest = []\n",
    "    cvx_hulls = []\n",
    "    for g_n, m_n in zip(geometry_names, model_names):\n",
    "        b = plant.GetBodyFrameIdIfExists(\n",
    "                                        plant.GetBodyByName(g_n, \n",
    "                                                            plant.GetModelInstanceByName(m_n)\n",
    "                                                            ).index())\n",
    "        bodies_of_interest +=[b]\n",
    "        ids = inspector.GetGeometries(b, Role.kProximity)\n",
    "        vp = [VPolytope(scene_graph.get_query_output_port().Eval(scene_graph_context), id) for id in ids]\n",
    "        verts = np.concatenate(tuple([v.vertices().T for v in vp]), axis=0)\n",
    "        mean = np.mean(verts,axis=0).reshape(1,-1)\n",
    "        cvx_hulls += [HPolyhedron(VPolytope(scaling*(verts.T- mean.T)+mean.T))]\n",
    "    return cvx_hulls, bodies_of_interest\n",
    "\n",
    "from pydrake.all import RotationMatrix, AngleAxis\n",
    "\n",
    "def sample_random_orientations(N, seed = 1230):\n",
    "    \"\"\"\n",
    "    sample entirely random angles from -pi to pi\n",
    "    \"\"\"\n",
    "    #np.random.seed(seed)\n",
    "    vecs = np.random.randn(N,3)\n",
    "    vecs = vecs/np.linalg.norm(vecs)\n",
    "    angs = 2*np.pi*(np.random.rand(N)-0.5)\n",
    "    rotmats = [AngleAxis(ang, ax) for ang, ax in zip(angs, vecs)]\n",
    "    return rotmats\n",
    "\n",
    "def solve_ik_problem(poses,\n",
    "                     q0, \n",
    "                     frames, \n",
    "                     offsets, \n",
    "                     plant_ik, \n",
    "                     plant_context_ik, \n",
    "                     collision_free = True,\n",
    "                     track_orientation = True,\n",
    "                     checker = None):\n",
    "    \n",
    "    ik = InverseKinematics(plant_ik, plant_context_ik)\n",
    "    for pose, f, o in zip(poses, frames, offsets):\n",
    "        ik.AddPositionConstraint(\n",
    "            f,\n",
    "            o,\n",
    "            plant_ik.world_frame(),\n",
    "            pose.translation()-0.02,\n",
    "            pose.translation()+0.02,\n",
    "        )\n",
    "        if track_orientation:\n",
    "            ik.AddOrientationConstraint(\n",
    "                f,\n",
    "                RotationMatrix(),\n",
    "                plant_ik.world_frame(),\n",
    "                pose.rotation(),\n",
    "                0.1,\n",
    "            )\n",
    "    if True:\n",
    "        ik.AddMinimumDistanceLowerBoundConstraint(0.01, 0.005)\n",
    "    prog = ik.get_mutable_prog()\n",
    "    q = ik.q()\n",
    "    prog.AddQuadraticErrorCost(np.identity(len(q)), q0, q)\n",
    "    prog.SetInitialGuess(q, q0)\n",
    "    result = Solve(ik.prog())\n",
    "    if result.is_success():\n",
    "            solution = result.GetSolution(q)\n",
    "            if checker.CheckConfigCollisionFree(solution):\n",
    "                return solution\n",
    "            else:\n",
    "                print(\"COLLISION DETECTED\")\n",
    "    return None\n",
    "\n",
    "def task_space_sampler(num_points_seed_q0_t0_ax_al_tuple, \n",
    "                       regions,  \n",
    "                       plant_builder,\n",
    "                       frame_names,\n",
    "                       offsets, \n",
    "                       cvx_hulls_of_ROI,\n",
    "                       ts_min, #bounding box in task space to sample in\n",
    "                       ts_max,\n",
    "                       collision_free = True, \n",
    "                       track_orientation = True,\n",
    "                       MAXIT = int(1e4)):\n",
    "        n_points = num_points_seed_q0_t0_ax_al_tuple[0]\n",
    "        seed = num_points_seed_q0_t0_ax_al_tuple[1]\n",
    "        q0 = num_points_seed_q0_t0_ax_al_tuple[2]\n",
    "        t0 = num_points_seed_q0_t0_ax_al_tuple[3]\n",
    "        preferred_axis_alignment = num_points_seed_q0_t0_ax_al_tuple[4]\n",
    "        plant_ik, _, diagram_ik, _, plant_context_ik, _ = plant_builder(use_rohan_scenario=USE_ROHAN)\n",
    "        frames = [plant_ik.GetFrameByName(f) for f in frame_names]\n",
    "\n",
    "        robot_instances = [plant_ik.GetModelInstanceByName(\"iiwa\"), plant_ik.GetModelInstanceByName(\"wsg\")]\n",
    "\n",
    "        checker = SceneGraphCollisionChecker(model = diagram_ik, \n",
    "                    robot_model_instances = robot_instances,\n",
    "                    edge_step_size = 0.125)\n",
    "    \n",
    "        q_points = [q0]\n",
    "        t_points = [t0]\n",
    "        np.random.seed(seed)    \n",
    "        if preferred_axis_alignment is not None:\n",
    "            sc = np.array([0.2, 1, 1])\n",
    "           \n",
    "        for i in tqdm(range(n_points)):\n",
    "            for it in range(MAXIT):\n",
    "                if preferred_axis_alignment is not None:\n",
    "                    vecs = np.random.randn(1,3)*sc\n",
    "                    vecs = vecs/np.linalg.norm(vecs)\n",
    "                    angs = 1.2*(np.random.randn(1))\n",
    "                    if preferred_axis_alignment ==2:\n",
    "                        rot_corr = RotationMatrix.MakeXRotation(-np.pi/2)\n",
    "                    # if preferred_axis_alignment == 1:\n",
    "                    #     rot_corr = RotationMatrix.MakeYRotation(np.pi/2)\n",
    "                    if preferred_axis_alignment == 0:\n",
    "                        rot_corr = RotationMatrix.MakeZRotation(-np.pi/2)\n",
    "                    rand_rot = RotationMatrix(AngleAxis(angs[0], vecs[0,:]) )\n",
    "                    rotmat =  rot_corr@rand_rot\n",
    "                else:  \n",
    "                    rotmat = sample_random_orientations(1)[0]\n",
    "                t_point = sample_in_union_of_polytopes(1, cvx_hulls_of_ROI, [ts_min, ts_max]).squeeze() #t_min + t_diff*np.random.rand(3)\n",
    "                idx_closest = np.argmin(np.linalg.norm(np.array(t_points)-t_point))\n",
    "                q0 = q_points[idx_closest]\n",
    "                res = solve_ik_problem([RigidTransform(rotmat, t_point)], \n",
    "                                       q0= q0,\n",
    "                                       plant_ik=plant_ik,\n",
    "                                       plant_context_ik=plant_context_ik,\n",
    "                                       frames=frames,\n",
    "                                       offsets=offsets,\n",
    "                                       collision_free = collision_free,\n",
    "                                       track_orientation =track_orientation,\n",
    "                                       checker = checker)\n",
    "                if res is not None and not point_in_regions(res, regions):\n",
    "                    q_points.append(res)\n",
    "                    t_points.append(t_point)\n",
    "                    #print(f\"found point {i} seed {seed}\")\n",
    "                    break\n",
    "                #else:\n",
    "                #    print(f\"failed seed {seed}\")\n",
    "                if it ==MAXIT:\n",
    "                    print(\"[SAMPLER] CANT FIND IK SOLUTION\")\n",
    "                    return None, None, True\n",
    "        return np.array(q_points[1:]), np.array(t_points[1:]), False    \n",
    "\n",
    "def task_space_sampler_mp(n_points, \n",
    "                          regions,  \n",
    "                          plant_builder,\n",
    "                          frame_names,\n",
    "                          offsets,\n",
    "                          cvx_hulls_of_ROI,\n",
    "                          ts_min,\n",
    "                          ts_max, \n",
    "                          q0 = None, \n",
    "                          t0 = None,\n",
    "                          collision_free = True, \n",
    "                          track_orientation = True,\n",
    "                          axis_alignment = None\n",
    "                          ):\n",
    "        \n",
    "        processes = mp.cpu_count()\n",
    "        pool = mp.Pool(processes=processes)\n",
    "        pieces = np.array_split(np.ones(n_points), processes)\n",
    "        if q0 is not None:\n",
    "            n_chunks = [[int(np.sum(p)), np.random.randint(1000), q0, t0, axis_alignment] for p in pieces]\n",
    "        else:\n",
    "             plant_ik, _, _, _, plant_context_ik, _ = plant_builder(use_rohan_scenario=USE_ROHAN)\n",
    "             qmax = plant_ik.GetPositionUpperLimits()\n",
    "             qmin = plant_ik.GetPositionLowerLimits()\n",
    "             dim = len(qmax)\n",
    "             qdiff =qmax- qmin\n",
    "             chunks = []\n",
    "             for p in pieces:\n",
    "                q0 = qdiff*np.random.rand(dim) +qmin\n",
    "                plant_ik.SetPositions(plant_context_ik, q0)\n",
    "                t0 = plant_ik.EvalBodyPoseInWorld(plant_context_ik,  plant_ik.GetBodyByName(frame_names[0])).translation()   \n",
    "                chunks.append([int(np.sum(p)), np.random.randint(1000), q0, t0])\n",
    "        q_pts = []\n",
    "        t_pts = []\n",
    "        is_full = False\n",
    "        SAMPLERHANDLE = partial(task_space_sampler, \n",
    "                                regions = regions, \n",
    "                                plant_builder = plant_builder,\n",
    "                                frame_names = frame_names, \n",
    "                                offsets = offsets,\n",
    "                                cvx_hulls_of_ROI = cvx_hulls_of_ROI,\n",
    "                                ts_min = ts_min, #bounding box in task space to sample in\n",
    "                                ts_max = ts_max,\n",
    "                                collision_free = collision_free,\n",
    "                                track_orientation = track_orientation) \n",
    "        #print(n_chunks)\n",
    "        results = pool.map(SAMPLERHANDLE, n_chunks)\n",
    "        for r in results:\n",
    "            if len(r[0]):\n",
    "                q_pts.append(r[0])\n",
    "                t_pts.append(r[1])\n",
    "                is_full |= r[2]\n",
    "        return np.concatenate(tuple(q_pts), axis = 0), np.concatenate(tuple(t_pts), axis = 0), is_full, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohanbosworth/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import colorsys\n",
    "from fractions import Fraction\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\"\n",
    "    color stuff\n",
    "    \"\"\"\n",
    "    # Remove the leading '#' if present\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "\n",
    "    # Ensure the input is a valid hex color code\n",
    "    if len(hex_color) != 6:\n",
    "        raise ValueError(\"Invalid hex color code\")\n",
    "\n",
    "    # Extract the individual color components\n",
    "    red = int(hex_color[0:2], 16)/255.0\n",
    "    green = int(hex_color[2:4], 16)/255.0\n",
    "    blue = int(hex_color[4:6], 16)/255.0\n",
    "\n",
    "    return red, green, blue\n",
    "\n",
    "def generate_distinct_colors(n, rgb = False):\n",
    "    \"\"\"\n",
    "    many colors\n",
    "    \"\"\"\n",
    "    cmap = plt.cm.get_cmap('hsv', n)  # Choose a colormap\n",
    "    colors = [mcolors.rgb2hex(cmap(i)[:3]) for i in range(n)]  # Convert colormap to hexadecimal colors\n",
    "    if rgb:\n",
    "        return [hex_to_rgb(c) for c in colors]\n",
    "    else:\n",
    "        return colors\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydrake.all import (Hyperellipsoid,\n",
    "                         MathematicalProgram,\n",
    "                         Solve, \n",
    "                         le,\n",
    "                         ge,\n",
    "                         eq,\n",
    "                         MosekSolver,\n",
    "                         VPolytope,\n",
    "                         PiecewisePolynomial,\n",
    "                         SolverOptions,\n",
    "                         CommonSolverOption,\n",
    "                         HPolyhedron)\n",
    "import pydrake.symbolic as sym\n",
    "def get_AABB_limits(hpoly, dim=3):\n",
    "    max_limits = []\n",
    "    min_limits = []\n",
    "    A = hpoly.A()\n",
    "    b = hpoly.b()\n",
    "\n",
    "    for idx in range(dim):\n",
    "        aabbprog = MathematicalProgram()\n",
    "        x = aabbprog.NewContinuousVariables(dim, 'x')\n",
    "        cost = x[idx]\n",
    "        aabbprog.AddCost(cost)\n",
    "        aabbprog.AddConstraint(le(A @ x, b))\n",
    "       \n",
    "        result = Solve(aabbprog)\n",
    "        min_limits.append(result.get_optimal_cost() - 0.1)\n",
    "        aabbprog = MathematicalProgram()\n",
    "        x = aabbprog.NewContinuousVariables(dim, 'x')\n",
    "        cost = -x[idx]\n",
    "        aabbprog.AddCost(cost)\n",
    "        aabbprog.AddConstraint(le(A @ x, b))\n",
    "        result = Solve(aabbprog)\n",
    "        max_limits.append(-result.get_optimal_cost() + 0.1)\n",
    "    return max_limits, min_limits\n",
    "\n",
    "\n",
    "def get_AABB_cvxhull(regions):\n",
    "    vps = [VPolytope(r).vertices().T for r in regions]\n",
    "    cvxh = HPolyhedron(VPolytope(np.concatenate(tuple(vps), axis=0).T))\n",
    "    max, min = get_AABB_limits(cvxh, dim = 3)    \n",
    "    return np.array(min), np.array(max), cvxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import Rgba, TriangleSurfaceMesh, SurfaceTriangle\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def plot_hpoly3d_2(meshcat, name, hpoly, color, wireframe = True, resolution = -1, offset = np.zeros(3)):\n",
    "        #meshcat wierdness of double rendering\n",
    "        hpoly = HPolyhedron(hpoly.A(), hpoly.b() + 0.05*(np.random.rand(hpoly.b().shape[0])-0.5))\n",
    "        verts = VPolytope(hpoly).vertices().T\n",
    "        hull = ConvexHull(verts)\n",
    "        triangles = []\n",
    "        for s in hull.simplices:\n",
    "            triangles.append(s)\n",
    "        tri_drake = [SurfaceTriangle(*t) for t in triangles]\n",
    "        # obj = self[name]\n",
    "        # objwf = self[name+'wf']\n",
    "        # col = to_hex(color)\n",
    "        #material = MeshLambertMaterial(color=col, opacity=opacity)\n",
    "        color2 = Rgba(0.8*color.r(), 0.8*color.g(), 0.8*color.b(), color.a())\n",
    "        meshcat.SetObject(name, TriangleSurfaceMesh(tri_drake, verts+offset.reshape(-1,3)),\n",
    "                                color, wireframe=False)\n",
    "        meshcat.SetObject(name+'wf', TriangleSurfaceMesh(tri_drake, verts+offset.reshape(-1,3)),\n",
    "                                color2, wireframe=True)\n",
    "        # #obj.set_object(TriangularMeshGeometry(verts, triangles), material)\n",
    "        # material = MeshLambertMaterial(color=col, opacity=0.95, wireframe=True)\n",
    "        # objwf.set_object(TriangularMeshGeometry(verts, triangles), material)\n",
    "\n",
    "def plot_regions(meshcat, regions, ellipses = None,\n",
    "                     region_suffix = '', colors = None,\n",
    "                     wireframe = False,\n",
    "                     opacity = 0.7,\n",
    "                     fill = True,\n",
    "                     line_width = 10,\n",
    "                     darken_factor = .2,\n",
    "                     el_opacity = 0.3,\n",
    "                     resolution = 30,\n",
    "                     offset = np.zeros(3)):\n",
    "        if colors is None:\n",
    "            colors = generate_distinct_colors(len(regions))\n",
    "\n",
    "        for i, region in enumerate(regions):\n",
    "            c = Rgba(*[col for col in colors[i]],opacity)\n",
    "            prefix = f\"/iris/regions{region_suffix}/{i}\"\n",
    "            name = prefix + \"/hpoly\"\n",
    "            if region.ambient_dimension() == 3:\n",
    "                # plot_hpoly3d(meshcat, name, region,\n",
    "                #                   c, wireframe = wireframe, resolution = resolution, offset = offset)\n",
    "                plot_hpoly3d_2(meshcat, name, region,\n",
    "                                  c, wireframe = wireframe, resolution = resolution, offset = offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import Sphere\n",
    "col_col =  Rgba(0.8, 0.0, 0, 0.5)    \n",
    "col_free =  Rgba(0.0, 0.8, 0.5, 0.5) \n",
    "\n",
    "def showres(qvis):\n",
    "    plant.SetPositions(plant_context, qvis)\n",
    "    diagram.ForcedPublish(diagram_context)\n",
    "    query = plant.get_geometry_query_input_port().Eval(plant_context)\n",
    "    col = query.HasCollisions()\n",
    "    if col:\n",
    "        meshcat.SetObject(f\"/drake/visualizer/col\",\n",
    "                                   Sphere(0.2),\n",
    "                                   col_col)\n",
    "    else:\n",
    "        meshcat.SetObject(f\"/drake/visualizer/col\",\n",
    "                                   Sphere(0.2),\n",
    "                                   col_free)\n",
    "    meshcat.SetTransform(f\"/drake/visualizer/col\",\n",
    "                                   RigidTransform(RotationMatrix(),\n",
    "                                                  np.array([0,0,2])))\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1163690767471b849673714618ac0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q0', max=2.9373894, min=-2.9373894, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d30f64b840a4bc4b619b227e123874b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q1', max=2.0734559999999997, min=-2.0734559999999997, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f138e5f78bf34cadacdbbe0b50806cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q2', max=2.9373894, min=-2.9373894, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a80c5e0cfe43a1a3466c143465a4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q3', max=2.0734559999999997, min=-2.0734559999999997, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfa1f918ce14ed18f938558154e4e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q4', max=2.9373894, min=-2.9373894, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8562a71f42c9409b85a66f0f8721d613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q5', max=2.0734559999999997, min=-2.0734559999999997, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882c717442e442eeb5ddd3e26c3828b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='q6', max=3.0237867, min=-3.0237867, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "q = np.zeros(plant.num_positions()) \n",
    "sliders = []\n",
    "for i in range(plant.num_positions()):\n",
    "    q_low = plant.GetPositionLowerLimits()[i]*0.99\n",
    "    q_high = plant.GetPositionUpperLimits()[i]*0.99\n",
    "    sliders.append(widgets.FloatSlider(min=q_low, max=q_high, value=0, step=0.001, description=f\"q{i}\"))\n",
    "\n",
    "def handle_slider_change(change, idx):\n",
    "    q[idx] = change['new']\n",
    "    showres(q)\n",
    "idx = 0\n",
    "for slider in sliders:\n",
    "    slider.observe(partial(handle_slider_change, idx = idx), names='value')\n",
    "    idx+=1\n",
    "\n",
    "for slider in sliders:\n",
    "    display(slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0003894, -0.000456 , -0.0003894, -0.000456 , -0.0003894,\n",
       "       -0.000456 ,  0.0002133])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2270808/2708891333.py:31: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('hsv', n)  # Choose a colormap\n"
     ]
    }
   ],
   "source": [
    "\n",
    "offset_size = 0.01\n",
    "geom_names = ['bin_base', \n",
    "              'bin_base', \n",
    "              'shelves_body',\n",
    "              ]\n",
    "model_names = ['binL', \n",
    "               'binR', \n",
    "               'shelves',\n",
    "               ]\n",
    "default_pos = [np.array([-1.37338913e+00,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "               np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "       np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "       np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "       np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "       np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "       np.array([ 9.46108689e-02,  3.33548849e-01, -1.89389131e-01, -1.50545115e+00,\n",
    "       -3.89131106e-04,  1.23654885e+00,  2.17070920e-04]),\n",
    "               \n",
    "               ]\n",
    "approach_dir = [2, \n",
    "                2, \n",
    "                2,\n",
    "                2, 2, 2, 2\n",
    "                ] \n",
    "approach_sign = [1,1,1, 1, 1, 1]\n",
    "ts_samplers = []\n",
    "cols = generate_distinct_colors(2*len(model_names), rgb = True)[1:]\n",
    "AABB_sampling_regions = []\n",
    "vertBods = []\n",
    "for i, (g, m) in enumerate(zip(geom_names, model_names)):\n",
    "    cvx_hulls_of_ROI_unsc, bodies = get_cvx_hulls_of_bodies([g], [m], plant, scene_graph, scene_graph_context, scaling = 1.0)\n",
    "    vertsA = [VPolytope(c).vertices().T for c in cvx_hulls_of_ROI_unsc]\n",
    "    vertBods.append(vertsA[0])\n",
    "    cvx_hulls_of_ROI = cvx_hulls_of_ROI_unsc\n",
    "\n",
    "vertBodsNp = np.array(vertBods)\n",
    "\n",
    "if vertBods[2].any():\n",
    "    vertShelves = vertBodsNp[-1]\n",
    "    vertBodsNp = vertBodsNp[:-1]\n",
    "    vertBods = vertBods[:-1]\n",
    "    minz = np.min(vertShelves[:,2])\n",
    "    maxz = np.max(vertShelves[:,2])\n",
    "    incrVal = (abs(minz) + abs(maxz))/3\n",
    "    for j in range(3):\n",
    "        addVerts = vertShelves.copy()\n",
    "        for i in range(len(addVerts)):\n",
    "            if addVerts[i][2] == minz:\n",
    "                addVerts[i][2] = minz + incrVal * j\n",
    "            if addVerts[i][2] == maxz:\n",
    "                addVerts[i][2] = minz + incrVal * (j+1)\n",
    "        \n",
    "        vertBods.append(addVerts)\n",
    "\n",
    "for i, verts in enumerate(vertBods):\n",
    "    cvx_hulls_of_ROI = []\n",
    "    verts = [verts]\n",
    "    for v in verts:\n",
    "        offset = approach_sign[i]*(np.sign(v[:,approach_dir[i]] - np.mean(v[:,approach_dir[i]]))==approach_sign[i])*offset_size\n",
    "        v[:,approach_dir[i]] += offset #scale*(v[:,approach_dir[i]] - np.mean(v[:,approach_dir[i]])) +  np.mean(v[:,approach_dir[i]])\n",
    "        cvx_hulls_of_ROI.append(HPolyhedron(VPolytope(v.T)))\n",
    "    ts_min, ts_max, cvxh_hpoly = get_AABB_cvxhull(cvx_hulls_of_ROI)\n",
    "    AABB_sampling_regions.append([ts_min, ts_max])\n",
    "    plot_regions(meshcat, cvx_hulls_of_ROI, region_suffix='',opacity=0.2, colors=[cols[i]])\n",
    "    q0  = default_pos[i] #np.zeros(7)\n",
    "    plant.SetPositions(plant_context, q0)\n",
    "    plant.ForcedPublish(plant_context)\n",
    "    showres(q0)\n",
    "    t0 = plant.EvalBodyPoseInWorld(plant_context,  plant.GetBodyByName(\"body\")).translation()       \n",
    "    sample_handle_ts = partial(task_space_sampler_mp,\n",
    "                            q0 = q0,\n",
    "                            t0 = t0,\n",
    "                            plant_builder = plant_builder,\n",
    "                            frame_names = ['body'],\n",
    "                            offsets = [np.array([0,0.1,0])],\n",
    "                            cvx_hulls_of_ROI =cvx_hulls_of_ROI,\n",
    "                            ts_min = ts_min,\n",
    "                            ts_max = ts_max,\n",
    "                            collision_free = True,\n",
    "                            track_orientation = True,\n",
    "                            axis_alignment = None #approach_dir[i]\n",
    "                            )\n",
    "    ts_samplers.append(sample_handle_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n"
     ]
    }
   ],
   "source": [
    "robot_instances = [plant.GetModelInstanceByName(\"iiwa\"), plant.GetModelInstanceByName(\"wsg\")]\n",
    "checker = SceneGraphCollisionChecker(model = diagram, \n",
    "                    robot_model_instances = robot_instances,\n",
    "                    edge_step_size = 0.125)\n",
    "\n",
    "def vgraph(points, checker, parallelize):\n",
    "    ad_mat = VisibilityGraph(checker.Clone(), np.array(points).T, parallelize = parallelize)\n",
    "    N = ad_mat.shape[0]\n",
    "    for i in range(N):\n",
    "        ad_mat[i,i] = False\n",
    "    #TODO: need to make dense for now to avoid wierd nx bugs for saving the metis file.\n",
    "    return  ad_mat\n",
    "vgraph_handle = partial(vgraph, checker = checker, parallelize = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import MaxCliqueSolverViaGreedy\n",
    "\n",
    "def compute_double_greedy_clique_partition(adj_mat, min_cliuqe_size, worklimit =100):\n",
    "    cliques = []\n",
    "    done = False\n",
    "    adj_curr = adj_mat.copy()\n",
    "    #adj_curr = 1- adj_curr\n",
    "    #np.fill_diagonal(adj_curr, 0)\n",
    "    for i in range(adj_curr.shape[0]):\n",
    "        adj_curr[i,i] = False\n",
    "    ind_curr = np.arange(adj_curr.shape[0])\n",
    "    solver = MaxCliqueSolverViaGreedy()\n",
    "    while not done:\n",
    "        #val, ind_max_clique_local = solve_max_independent_set_integer(adj_curr, worklimit=worklimit) #solve_max_independet_set_KAMIS(adj_curr, maxtime = 5) #\n",
    "        maximal_clique_bools = solver.SolveMaxClique(adj_curr)\n",
    "        ind_max_clique_local = np.where(maximal_clique_bools)[0]\n",
    "        #non_max_ind_local = np.arange(len(adj_curr))\n",
    "        #non_max_ind_local = np.delete(non_max_ind_local, ind_max_clique_local, None)\n",
    "        index_max_clique_global = np.array([ind_curr[i] for i in ind_max_clique_local])\n",
    "        cliques.append(index_max_clique_global.reshape(-1))\n",
    "        adj_curr = np.delete(adj_curr, ind_max_clique_local, 0)\n",
    "        adj_curr = np.delete(adj_curr, ind_max_clique_local, 1)\n",
    "        ind_curr = np.delete(ind_curr, ind_max_clique_local)\n",
    "        if len(adj_curr) == 0 or len(cliques[-1])<min_cliuqe_size:\n",
    "            done = True\n",
    "    return cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.58it/s]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.12s/it]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.16s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.59s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.51s/it]\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.28s/it]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n",
      "\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.22s/it]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "INFO:drake:Allocating contexts to support implicit context parallelism 20\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "\n",
    "Npts = 10\n",
    "seed = 5\n",
    "if f\"SAVVA_{Npts}_{offset_size}_{seed}.pkl\" in os.listdir('./tmp'):\n",
    "    with open(f\"./tmp/7DOFBINS_{Npts}_{offset_size}_{seed}.pkl\", 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        q_obj = d['q_obj']\n",
    "        t_obj = d['t_obj']\n",
    "        q_tot = d['q_tot']\n",
    "        t_tot = d['t_tot']        \n",
    "        ad_mat = d['ad_obj']\n",
    "        ad_tot = d['ad_tot']\n",
    "        cliques_obj = d['cliques_obj']\n",
    "        cliques_tot = d['cliques_tot']\n",
    "else:\n",
    "    q_obj = []\n",
    "    t_obj = []\n",
    "    ad_obj = []\n",
    "    cliques_obj = []\n",
    "    for sh in ts_samplers:\n",
    "        q, t, _, res = sh(Npts,[])\n",
    "        ad_mat = vgraph_handle(q)\n",
    "        q_obj +=[q]\n",
    "        t_obj +=[t]\n",
    "        ad_obj +=[ad_mat]\n",
    "        cliques_obj += [compute_double_greedy_clique_partition(adj_mat=ad_mat.toarray(), min_cliuqe_size=10)]\n",
    "    t_tot = np.concatenate(tuple(t_obj))\n",
    "    q_tot = np.concatenate(tuple(q_obj))\n",
    "    ad_tot = vgraph_handle(np.concatenate(tuple(q_obj), axis= 0))\n",
    "    #cliques_tot = compute_greedy_clique_partition(ad_tot.toarray(), min_cliuqe_size=10)\n",
    "    cliques_tot = compute_double_greedy_clique_partition(ad_tot.toarray(), min_cliuqe_size=10)\n",
    "    with open(f\"./tmp/7DOFBINS_{Npts}_{offset_size}_{seed}.pkl\", 'wb') as f:\n",
    "        pickle.dump({'q_obj':q_obj, \n",
    "                     't_obj':t_obj, \n",
    "                     't_tot': t_tot, \n",
    "                     'q_tot': q_tot, \n",
    "                     'ad_obj': ad_obj, \n",
    "                     'ad_tot' : ad_tot,\n",
    "                     'cliques_obj': cliques_obj, \n",
    "                     'cliques_tot': cliques_tot}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_array_to_3d(arr, val=0.):\n",
    "    if arr.shape[0] < 3:\n",
    "        arr = np.append(arr, val * np.ones((3 - arr.shape[0])))\n",
    "    return arr\n",
    "def plot_point(point, meshcat_instance, name,\n",
    "               color=Rgba(0.06, 0.0, 0, 1), radius=0.01):\n",
    "    meshcat_instance.SetObject(name,\n",
    "                               Sphere(radius),\n",
    "                               color)\n",
    "    meshcat_instance.SetTransform(name, RigidTransform(\n",
    "        RotationMatrix(), stretch_array_to_3d(point)))\n",
    "    \n",
    "\n",
    "def plot_points(meshcat, points, name, size = 0.05, color = Rgba(0.06, 0.0, 0, 1)):\n",
    "    for i, pt in enumerate(points):\n",
    "        n_i = name+f\"/pt{i}\"\n",
    "        plot_point(pt, meshcat, n_i, color = color, radius=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pts in enumerate(t_obj):\n",
    "    plot_points(meshcat, pts, f'task_space_pts{i}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(0)\n",
    "print(len(q_obj))\n",
    "for q in q_obj[4]:\n",
    "    showres(q)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct regions in bins\n",
    "ellipsoids_obj = []\n",
    "for q_bin, clique_decomp in zip(q_obj, cliques_obj):\n",
    "    ellipsoids_bin = []\n",
    "    for cl in clique_decomp:\n",
    "        if len(cl)>=8:\n",
    "            points_clique = q_bin[cl]\n",
    "            ellipsoid = Hyperellipsoid.MinimumVolumeCircumscribedEllipsoid(points_clique.T)\n",
    "            ellipsoids_bin.append(ellipsoid)\n",
    "    ellipsoids_obj.append(ellipsoids_bin)\n",
    "\n",
    "#run iris on ellipsoids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([1, 3])], [array([0])]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliques_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
